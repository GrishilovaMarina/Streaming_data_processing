{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Повторить чтение файлов со своими файлами со своей схемой.\n",
        "##Создать свой топик/топики, загрузить туда через консоль осмысленные данные с kaggle. Лучше в формате json. Много сообщений не нужно, достаточно штук 10-100.\n",
        "##Прочитать свой топик так же, как на уроке.\n"
      ],
      "metadata": {
        "id": "b7xmUgNmK75a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8u6eiVeK194",
        "outputId": "234b616e-b8c4-487e-b648-754950093c27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "Djy8WxASLK7r"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "K1FjViXhLVg2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "rH5mgSjAMmEa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download joebeachcapital/gpa-and-iq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-owqDvYNMukh",
        "outputId": "885d1c15-9e94-4965-8b3e-8bddd03ac5cc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading gpa-and-iq.zip to /content\n",
            "\r  0% 0.00/795 [00:00<?, ?B/s]\n",
            "\r100% 795/795 [00:00<00:00, 2.27MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip /content/gpa-and-iq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KORCuQJ_Sc7x",
        "outputId": "f32119be-363b-45af-d15f-e8cfe0b8a578"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/gpa-and-iq.zip\n",
            "  inflating: gpa_iq.csv              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('gpa_iq.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "YkSo0Vo4R4Y-",
        "outputId": "f86730f5-7029-426e-8bd7-7acc741ccd6e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    obs    gpa   iq  gender  concept\n",
              "0     1  7.940  111       2       67\n",
              "1     2  8.292  107       2       43\n",
              "2     3  4.643  100       2       52\n",
              "3     4  7.470  107       2       66\n",
              "4     5  8.882  114       1       58\n",
              "..  ...    ...  ...     ...      ...\n",
              "73   85  9.000  112       1       60\n",
              "74   86  9.500  112       1       70\n",
              "75   87  6.057  114       2       51\n",
              "76   88  6.057   93       1       21\n",
              "77   89  6.938  106       2       56\n",
              "\n",
              "[78 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c6837aff-e82d-4003-9e44-1f2a12b1a0b4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>obs</th>\n",
              "      <th>gpa</th>\n",
              "      <th>iq</th>\n",
              "      <th>gender</th>\n",
              "      <th>concept</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>7.940</td>\n",
              "      <td>111</td>\n",
              "      <td>2</td>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>8.292</td>\n",
              "      <td>107</td>\n",
              "      <td>2</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4.643</td>\n",
              "      <td>100</td>\n",
              "      <td>2</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>7.470</td>\n",
              "      <td>107</td>\n",
              "      <td>2</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>8.882</td>\n",
              "      <td>114</td>\n",
              "      <td>1</td>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>85</td>\n",
              "      <td>9.000</td>\n",
              "      <td>112</td>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>86</td>\n",
              "      <td>9.500</td>\n",
              "      <td>112</td>\n",
              "      <td>1</td>\n",
              "      <td>70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>87</td>\n",
              "      <td>6.057</td>\n",
              "      <td>114</td>\n",
              "      <td>2</td>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>88</td>\n",
              "      <td>6.057</td>\n",
              "      <td>93</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>89</td>\n",
              "      <td>6.938</td>\n",
              "      <td>106</td>\n",
              "      <td>2</td>\n",
              "      <td>56</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>78 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6837aff-e82d-4003-9e44-1f2a12b1a0b4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c6837aff-e82d-4003-9e44-1f2a12b1a0b4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c6837aff-e82d-4003-9e44-1f2a12b1a0b4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-661974ae-839d-40f4-a3be-8ef333054268\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-661974ae-839d-40f4-a3be-8ef333054268')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-661974ae-839d-40f4-a3be-8ef333054268 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E60rdbGpXroc",
        "outputId": "60277220-9b56-4b04-e178-6607881463d4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285388 sha256=0cfe3e77c12b6ccf2fdc2a85fed83ea8d6843767db8794618500122b281a3316\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -sSOL https://dlcdn.apache.org/kafka/3.5.0/kafka_2.13-3.5.0.tgz\n",
        "\n",
        "!tar -xzf kafka_2.13-3.5.0.tgz"
      ],
      "metadata": {
        "id": "1IdnUyxRYcqN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./kafka_2.13-3.5.0/bin/zookeeper-server-start.sh -daemon ./kafka_2.13-3.5.0/config/zookeeper.properties\n",
        "!./kafka_2.13-3.5.0/bin/kafka-server-start.sh -daemon ./kafka_2.13-3.5.0/config/server.properties\n",
        "!echo \"Waiting for 10 secs until kafka and zookeeper services are up and running\"\n",
        "!sleep 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIGEjGWDYjYs",
        "outputId": "734a2529-1760-4614-c2de-f20ee65adb2b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Waiting for 10 secs until kafka and zookeeper services are up and running\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ps -ef | grep kafka"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2a_FiDJgR7K",
        "outputId": "b44d91eb-f08b-4b52-fe56-f44ff04352a8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root        1256       1 23 06:24 ?        00:00:02 java -Xmx512M -Xms512M -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -XX:MaxInlineLevel=15 -Djava.awt.headless=true -Xlog:gc*:file=/content/kafka_2.13-3.5.0/bin/../logs/zookeeper-gc.log:time,tags:filecount=10,filesize=100M -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dkafka.logs.dir=/content/kafka_2.13-3.5.0/bin/../logs -Dlog4j.configuration=file:./kafka_2.13-3.5.0/bin/../config/log4j.properties -cp /content/kafka_2.13-3.5.0/bin/../libs/activation-1.1.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/argparse4j-0.7.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/audience-annotations-0.13.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/commons-cli-1.4.jar:/content/kafka_2.13-3.5.0/bin/../libs/commons-lang3-3.8.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/connect-api-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/connect-basic-auth-extension-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/connect-json-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/connect-mirror-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/connect-mirror-client-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/connect-runtime-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/connect-transforms-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/hk2-api-2.6.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/hk2-locator-2.6.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/hk2-utils-2.6.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/jackson-annotations-2.13.5.jar:/content/kafka_2.13-3.5.0/bin/../libs/jackson-core-2.13.5.jar:/content/kafka_2.13-3.5.0/bin/../libs/jackson-databind-2.13.5.jar:/content/kafka_2.13-3.5.0/bin/../libs/jackson-dataformat-csv-2.13.5.jar:/content/kafka_2.13-3.5.0/bin/../libs/jackson-datatype-jdk8-2.13.5.jar:/content/kafka_2.13-3.5.0/bin/../libs/jackson-jaxrs-base-2.13.5.jar:/content/kafka_2.13-3.5.0/bin/../libs/jackson-jaxrs-json-provider-2.13.5.jar:/content/kafka_2.13-3.5.0/bin/../libs/jackson-module-jaxb-annotations-2.13.5.jar:/content/kafka_2.13-3.5.0/bin/../libs/jackson-module-scala_2.13-2.13.5.jar:/content/kafka_2.13-3.5.0/bin/../libs/jakarta.activation-api-1.2.2.jar:/content/kafka_2.13-3.5.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/content/kafka_2.13-3.5.0/bin/../libs/jakarta.inject-2.6.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/content/kafka_2.13-3.5.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/content/kafka_2.13-3.5.0/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/content/kafka_2.13-3.5.0/bin/../libs/javassist-3.29.2-GA.jar:/content/kafka_2.13-3.5.0/bin/../libs/javax.activation-api-1.2.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/javax.annotation-api-1.3.2.jar:/content/kafka_2.13-3.5.0/bin/../libs/javax.servlet-api-3.1.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/jaxb-api-2.3.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/jersey-client-2.39.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/jersey-common-2.39.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/jersey-container-servlet-2.39.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/jersey-container-servlet-core-2.39.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/jersey-hk2-2.39.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/jersey-server-2.39.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/jetty-client-9.4.51.v20230217.jar:/content/kafka_2.13-3.5.0/bin/../libs/jetty-continuation-9.4.51.v20230217.jar:/content/kafka_2.13-3.5.0/bin/../libs/jetty-http-9.4.51.v20230217.jar:/content/kafka_2.13-3.5.0/bin/../libs/jetty-io-9.4.51.v20230217.jar:/content/kafka_2.13-3.5.0/bin/../libs/jetty-security-9.4.51.v20230217.jar:/content/kafka_2.13-3.5.0/bin/../libs/jetty-server-9.4.51.v20230217.jar:/content/kafka_2.13-3.5.0/bin/../libs/jetty-servlet-9.4.51.v20230217.jar:/content/kafka_2.13-3.5.0/bin/../libs/jetty-servlets-9.4.51.v20230217.jar:/content/kafka_2.13-3.5.0/bin/../libs/jetty-util-9.4.51.v20230217.jar:/content/kafka_2.13-3.5.0/bin/../libs/jetty-util-ajax-9.4.51.v20230217.jar:/content/kafka_2.13-3.5.0/bin/../libs/jline-3.22.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/jopt-simple-5.0.4.jar:/content/kafka_2.13-3.5.0/bin/../libs/jose4j-0.9.3.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka_2.13-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-clients-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-group-coordinator-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-log4j-appender-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-metadata-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-raft-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-server-common-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-shell-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-storage-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-storage-api-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-streams-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-streams-examples-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-streams-scala_2.13-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-streams-test-utils-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-tools-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-tools-api-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/lz4-java-1.8.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/maven-artifact-3.8.4.jar:/content/kafka_2.13-3.5.0/bin/../libs/metrics-core-2.2.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/metrics-core-4.1.12.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/netty-buffer-4.1.92.Final.jar:/content/kafka_2.13-3.5.0/bin/../libs/netty-codec-4.1.92.Final.jar:/content/kafka_2.13-3.5.0/bin/../libs/netty-common-4.1.92.Final.jar:/content/kafka_2.13-3.5.0/bin/../libs/netty-handler-4.1.92.Final.jar:/content/kafka_2.13-3.5.0/bin/../libs/netty-resolver-4.1.92.Final.jar:/content/kafka_2.13-3.5.0/bin/../libs/netty-transport-4.1.92.Final.jar:/content/kafka_2.13-3.5.0/bin/../libs/netty-transport-classes-epoll-4.1.92.Final.jar:/content/kafka_2.13-3.5.0/bin/../libs/netty-transport-native-epoll-4.1.92.Final.jar:/content/kafka_2.13-3.5.0/bin/../libs/netty-transport-native-unix-common-4.1.92.Final.jar:/content/kafka_2.13-3.5.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/content/kafka_2.13-3.5.0/bin/../libs/paranamer-2.8.jar:/content/kafka_2.13-3.5.0/bin/../libs/plexus-utils-3.3.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/reflections-0.9.12.jar:/content/kafka_2.13-3.5.0/bin/../libs/reload4j-1.2.25.jar:/content/kafka_2.13-3.5.0/bin/../libs/rocksdbjni-7.1.2.jar:/content/kafka_2.13-3.5.0/bin/../libs/scala-collection-compat_2.13-2.10.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/scala-java8-compat_2.13-1.0.2.jar:/content/kafka_2.13-3.5.0/bin/../libs/scala-library-2.13.10.jar:/content/kafka_2.13-3.5.0/bin/../libs/scala-logging_2.13-3.9.4.jar:/content/kafka_2.13-3.5.0/bin/../libs/scala-reflect-2.13.10.jar:/content/kafka_2.13-3.5.0/bin/../libs/slf4j-api-1.7.36.jar:/content/kafka_2.13-3.5.0/bin/../libs/slf4j-reload4j-1.7.36.jar:/content/kafka_2.13-3.5.0/bin/../libs/snappy-java-1.1.10.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/swagger-annotations-2.2.8.jar:/content/kafka_2.13-3.5.0/bin/../libs/trogdor-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/zookeeper-3.6.4.jar:/content/kafka_2.13-3.5.0/bin/../libs/zookeeper-jute-3.6.4.jar:/content/kafka_2.13-3.5.0/bin/../libs/zstd-jni-1.5.5-1.jar org.apache.zookeeper.server.quorum.QuorumPeerMain ./kafka_2.13-3.5.0/config/zookeeper.properties\n",
            "root        1620       1 77 06:24 ?        00:00:07 java -Xmx1G -Xms1G -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -XX:MaxInlineLevel=15 -Djava.awt.headless=true -Xlog:gc*:file=/content/kafka_2.13-3.5.0/bin/../logs/kafkaServer-gc.log:time,tags:filecount=10,filesize=100M -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dkafka.logs.dir=/content/kafka_2.13-3.5.0/bin/../logs -Dlog4j.configuration=file:./kafka_2.13-3.5.0/bin/../config/log4j.properties -cp /content/kafka_2.13-3.5.0/bin/../libs/activation-1.1.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/argparse4j-0.7.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/audience-annotations-0.13.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/commons-cli-1.4.jar:/content/kafka_2.13-3.5.0/bin/../libs/commons-lang3-3.8.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/connect-api-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/connect-basic-auth-extension-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/connect-json-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/connect-mirror-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/connect-mirror-client-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/connect-runtime-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/connect-transforms-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/hk2-api-2.6.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/hk2-locator-2.6.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/hk2-utils-2.6.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/jackson-annotations-2.13.5.jar:/content/kafka_2.13-3.5.0/bin/../libs/jackson-core-2.13.5.jar:/content/kafka_2.13-3.5.0/bin/../libs/jackson-databind-2.13.5.jar:/content/kafka_2.13-3.5.0/bin/../libs/jackson-dataformat-csv-2.13.5.jar:/content/kafka_2.13-3.5.0/bin/../libs/jackson-datatype-jdk8-2.13.5.jar:/content/kafka_2.13-3.5.0/bin/../libs/jackson-jaxrs-base-2.13.5.jar:/content/kafka_2.13-3.5.0/bin/../libs/jackson-jaxrs-json-provider-2.13.5.jar:/content/kafka_2.13-3.5.0/bin/../libs/jackson-module-jaxb-annotations-2.13.5.jar:/content/kafka_2.13-3.5.0/bin/../libs/jackson-module-scala_2.13-2.13.5.jar:/content/kafka_2.13-3.5.0/bin/../libs/jakarta.activation-api-1.2.2.jar:/content/kafka_2.13-3.5.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/content/kafka_2.13-3.5.0/bin/../libs/jakarta.inject-2.6.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/content/kafka_2.13-3.5.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/content/kafka_2.13-3.5.0/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/content/kafka_2.13-3.5.0/bin/../libs/javassist-3.29.2-GA.jar:/content/kafka_2.13-3.5.0/bin/../libs/javax.activation-api-1.2.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/javax.annotation-api-1.3.2.jar:/content/kafka_2.13-3.5.0/bin/../libs/javax.servlet-api-3.1.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/jaxb-api-2.3.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/jersey-client-2.39.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/jersey-common-2.39.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/jersey-container-servlet-2.39.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/jersey-container-servlet-core-2.39.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/jersey-hk2-2.39.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/jersey-server-2.39.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/jetty-client-9.4.51.v20230217.jar:/content/kafka_2.13-3.5.0/bin/../libs/jetty-continuation-9.4.51.v20230217.jar:/content/kafka_2.13-3.5.0/bin/../libs/jetty-http-9.4.51.v20230217.jar:/content/kafka_2.13-3.5.0/bin/../libs/jetty-io-9.4.51.v20230217.jar:/content/kafka_2.13-3.5.0/bin/../libs/jetty-security-9.4.51.v20230217.jar:/content/kafka_2.13-3.5.0/bin/../libs/jetty-server-9.4.51.v20230217.jar:/content/kafka_2.13-3.5.0/bin/../libs/jetty-servlet-9.4.51.v20230217.jar:/content/kafka_2.13-3.5.0/bin/../libs/jetty-servlets-9.4.51.v20230217.jar:/content/kafka_2.13-3.5.0/bin/../libs/jetty-util-9.4.51.v20230217.jar:/content/kafka_2.13-3.5.0/bin/../libs/jetty-util-ajax-9.4.51.v20230217.jar:/content/kafka_2.13-3.5.0/bin/../libs/jline-3.22.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/jopt-simple-5.0.4.jar:/content/kafka_2.13-3.5.0/bin/../libs/jose4j-0.9.3.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka_2.13-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-clients-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-group-coordinator-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-log4j-appender-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-metadata-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-raft-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-server-common-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-shell-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-storage-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-storage-api-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-streams-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-streams-examples-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-streams-scala_2.13-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-streams-test-utils-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-tools-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-tools-api-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/lz4-java-1.8.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/maven-artifact-3.8.4.jar:/content/kafka_2.13-3.5.0/bin/../libs/metrics-core-2.2.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/metrics-core-4.1.12.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/netty-buffer-4.1.92.Final.jar:/content/kafka_2.13-3.5.0/bin/../libs/netty-codec-4.1.92.Final.jar:/content/kafka_2.13-3.5.0/bin/../libs/netty-common-4.1.92.Final.jar:/content/kafka_2.13-3.5.0/bin/../libs/netty-handler-4.1.92.Final.jar:/content/kafka_2.13-3.5.0/bin/../libs/netty-resolver-4.1.92.Final.jar:/content/kafka_2.13-3.5.0/bin/../libs/netty-transport-4.1.92.Final.jar:/content/kafka_2.13-3.5.0/bin/../libs/netty-transport-classes-epoll-4.1.92.Final.jar:/content/kafka_2.13-3.5.0/bin/../libs/netty-transport-native-epoll-4.1.92.Final.jar:/content/kafka_2.13-3.5.0/bin/../libs/netty-transport-native-unix-common-4.1.92.Final.jar:/content/kafka_2.13-3.5.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/content/kafka_2.13-3.5.0/bin/../libs/paranamer-2.8.jar:/content/kafka_2.13-3.5.0/bin/../libs/plexus-utils-3.3.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/reflections-0.9.12.jar:/content/kafka_2.13-3.5.0/bin/../libs/reload4j-1.2.25.jar:/content/kafka_2.13-3.5.0/bin/../libs/rocksdbjni-7.1.2.jar:/content/kafka_2.13-3.5.0/bin/../libs/scala-collection-compat_2.13-2.10.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/scala-java8-compat_2.13-1.0.2.jar:/content/kafka_2.13-3.5.0/bin/../libs/scala-library-2.13.10.jar:/content/kafka_2.13-3.5.0/bin/../libs/scala-logging_2.13-3.9.4.jar:/content/kafka_2.13-3.5.0/bin/../libs/scala-reflect-2.13.10.jar:/content/kafka_2.13-3.5.0/bin/../libs/slf4j-api-1.7.36.jar:/content/kafka_2.13-3.5.0/bin/../libs/slf4j-reload4j-1.7.36.jar:/content/kafka_2.13-3.5.0/bin/../libs/snappy-java-1.1.10.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/swagger-annotations-2.2.8.jar:/content/kafka_2.13-3.5.0/bin/../libs/trogdor-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/zookeeper-3.6.4.jar:/content/kafka_2.13-3.5.0/bin/../libs/zookeeper-jute-3.6.4.jar:/content/kafka_2.13-3.5.0/bin/../libs/zstd-jni-1.5.5-1.jar kafka.Kafka ./kafka_2.13-3.5.0/config/server.properties\n",
            "root        1751     444  0 06:25 ?        00:00:00 /bin/bash -c ps -ef | grep kafka\n",
            "root        1753    1751  0 06:25 ?        00:00:00 grep kafka\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./kafka_2.13-3.5.0/bin/kafka-topics.sh --create --bootstrap-server 127.0.0.1:9092 --replication-factor 1 --partitions 2 --topic gpa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJV6W4Cx_TVo",
        "outputId": "09a321a8-f501-496e-e20e-3b7ece59d5c8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created topic gpa.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./kafka_2.13-3.5.0/bin/kafka-topics.sh  --list --bootstrap-server localhost:9092"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btI7WR8R_iPF",
        "outputId": "171f57ad-b4d5-49b8-dff6-84043e49f53a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gpa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import json\n",
        "\n",
        "csvfile = open('gpa_iq.csv', 'r')\n",
        "jsonfile = open('gpa_iq.json', 'w')\n",
        "\n",
        "\n",
        "reader = csv.DictReader(csvfile)\n",
        "for row in reader:\n",
        "   json.dump(row, jsonfile)\n",
        "   jsonfile.write('\\n')\n",
        "\n",
        "jsonfile = open('gpa_iq.json', 'w')"
      ],
      "metadata": {
        "id": "55G4isEsllL7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./kafka_2.13-3.5.0/bin/kafka-console-producer.sh --broker-list localhost:9092 --topic gpa < gpa_iq.json"
      ],
      "metadata": {
        "id": "HIy2Jrv2_pB8"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./kafka_2.13-3.5.0/bin/kafka-console-consumer.sh --topic gpa  --bootstrap-server localhost:9092 --from-beginning  --max-messages 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiKg_KiUAaK2",
        "outputId": "c9a337dd-5e6c-4df6-d4d5-5a01e85badbb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"obs\": \"1\", \"gpa\": \"7.94\", \"iq\": \"111\", \"gender\": \"2\", \"concept\": \"67\"}\n",
            "{\"obs\": \"2\", \"gpa\": \"8.292\", \"iq\": \"107\", \"gender\": \"2\", \"concept\": \"43\"}\n",
            "{\"obs\": \"3\", \"gpa\": \"4.643\", \"iq\": \"100\", \"gender\": \"2\", \"concept\": \"52\"}\n",
            "{\"obs\": \"4\", \"gpa\": \"7.47\", \"iq\": \"107\", \"gender\": \"2\", \"concept\": \"66\"}\n",
            "{\"obs\": \"5\", \"gpa\": \"8.882\", \"iq\": \"114\", \"gender\": \"1\", \"concept\": \"58\"}\n",
            "Processed a total of 5 messages\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export SPARK_KAFKA_VERSION=0.10\n",
        "!pyspark --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,org.apache.kafka:kafka-clients:3.3.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ft8Vvx-DPVzr",
        "outputId": "3eac9086-60bd-47dc-84d7-50e1cf53e769"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0] on linux\n",
            "Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n",
            ":: loading settings :: url = jar:file:/usr/local/lib/python3.10/dist-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
            "Ivy Default Cache set to: /root/.ivy2/cache\n",
            "The jars for the packages stored in: /root/.ivy2/jars\n",
            "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
            "org.apache.kafka#kafka-clients added as a dependency\n",
            ":: resolving dependencies :: org.apache.spark#spark-submit-parent-359ca99f-85f7-42b0-afe4-8f46090c0b97;1.0\n",
            "\tconfs: [default]\n",
            "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.3.1 in central\n",
            "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.3.1 in central\n",
            "\tfound org.apache.hadoop#hadoop-client-runtime;3.3.2 in central\n",
            "\tfound org.spark-project.spark#unused;1.0.0 in central\n",
            "\tfound org.apache.hadoop#hadoop-client-api;3.3.2 in central\n",
            "\tfound org.xerial.snappy#snappy-java;1.1.8.4 in central\n",
            "\tfound org.slf4j#slf4j-api;1.7.32 in central\n",
            "\tfound commons-logging#commons-logging;1.1.3 in central\n",
            "\tfound com.google.code.findbugs#jsr305;3.0.0 in central\n",
            "\tfound org.apache.commons#commons-pool2;2.11.1 in central\n",
            "\tfound org.apache.kafka#kafka-clients;3.3.1 in central\n",
            "\tfound com.github.luben#zstd-jni;1.5.2-1 in central\n",
            "\tfound org.lz4#lz4-java;1.8.0 in central\n",
            "\tfound org.slf4j#slf4j-api;1.7.36 in central\n",
            "downloading https://repo1.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.12/3.3.1/spark-sql-kafka-0-10_2.12-3.3.1.jar ...\n",
            "\t[SUCCESSFUL ] org.apache.spark#spark-sql-kafka-0-10_2.12;3.3.1!spark-sql-kafka-0-10_2.12.jar (455ms)\n",
            "downloading https://repo1.maven.org/maven2/org/apache/kafka/kafka-clients/3.3.1/kafka-clients-3.3.1.jar ...\n",
            "\t[SUCCESSFUL ] org.apache.kafka#kafka-clients;3.3.1!kafka-clients.jar (748ms)\n",
            "downloading https://repo1.maven.org/maven2/org/apache/spark/spark-token-provider-kafka-0-10_2.12/3.3.1/spark-token-provider-kafka-0-10_2.12-3.3.1.jar ...\n",
            "\t[SUCCESSFUL ] org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.3.1!spark-token-provider-kafka-0-10_2.12.jar (261ms)\n",
            "downloading https://repo1.maven.org/maven2/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar ...\n",
            "\t[SUCCESSFUL ] com.google.code.findbugs#jsr305;3.0.0!jsr305.jar (256ms)\n",
            "downloading https://repo1.maven.org/maven2/org/apache/commons/commons-pool2/2.11.1/commons-pool2-2.11.1.jar ...\n",
            "\t[SUCCESSFUL ] org.apache.commons#commons-pool2;2.11.1!commons-pool2.jar (260ms)\n",
            "downloading https://repo1.maven.org/maven2/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar ...\n",
            "\t[SUCCESSFUL ] org.spark-project.spark#unused;1.0.0!unused.jar (253ms)\n",
            "downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-client-runtime/3.3.2/hadoop-client-runtime-3.3.2.jar ...\n",
            "\t[SUCCESSFUL ] org.apache.hadoop#hadoop-client-runtime;3.3.2!hadoop-client-runtime.jar (1693ms)\n",
            "downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-client-api/3.3.2/hadoop-client-api-3.3.2.jar ...\n",
            "\t[SUCCESSFUL ] org.apache.hadoop#hadoop-client-api;3.3.2!hadoop-client-api.jar (1019ms)\n",
            "downloading https://repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.1.8.4/snappy-java-1.1.8.4.jar ...\n",
            "\t[SUCCESSFUL ] org.xerial.snappy#snappy-java;1.1.8.4!snappy-java.jar(bundle) (273ms)\n",
            "downloading https://repo1.maven.org/maven2/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar ...\n",
            "\t[SUCCESSFUL ] commons-logging#commons-logging;1.1.3!commons-logging.jar (254ms)\n",
            "downloading https://repo1.maven.org/maven2/com/github/luben/zstd-jni/1.5.2-1/zstd-jni-1.5.2-1.jar ...\n",
            "\t[SUCCESSFUL ] com.github.luben#zstd-jni;1.5.2-1!zstd-jni.jar (409ms)\n",
            "downloading https://repo1.maven.org/maven2/org/lz4/lz4-java/1.8.0/lz4-java-1.8.0.jar ...\n",
            "\t[SUCCESSFUL ] org.lz4#lz4-java;1.8.0!lz4-java.jar (263ms)\n",
            "downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.36/slf4j-api-1.7.36.jar ...\n",
            "\t[SUCCESSFUL ] org.slf4j#slf4j-api;1.7.36!slf4j-api.jar (254ms)\n",
            ":: resolution report :: resolve 18207ms :: artifacts dl 6433ms\n",
            "\t:: modules in use:\n",
            "\tcom.github.luben#zstd-jni;1.5.2-1 from central in [default]\n",
            "\tcom.google.code.findbugs#jsr305;3.0.0 from central in [default]\n",
            "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
            "\torg.apache.commons#commons-pool2;2.11.1 from central in [default]\n",
            "\torg.apache.hadoop#hadoop-client-api;3.3.2 from central in [default]\n",
            "\torg.apache.hadoop#hadoop-client-runtime;3.3.2 from central in [default]\n",
            "\torg.apache.kafka#kafka-clients;3.3.1 from central in [default]\n",
            "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.3.1 from central in [default]\n",
            "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.3.1 from central in [default]\n",
            "\torg.lz4#lz4-java;1.8.0 from central in [default]\n",
            "\torg.slf4j#slf4j-api;1.7.36 from central in [default]\n",
            "\torg.spark-project.spark#unused;1.0.0 from central in [default]\n",
            "\torg.xerial.snappy#snappy-java;1.1.8.4 from central in [default]\n",
            "\t:: evicted modules:\n",
            "\torg.apache.kafka#kafka-clients;2.8.1 by [org.apache.kafka#kafka-clients;3.3.1] in [default]\n",
            "\torg.slf4j#slf4j-api;1.7.32 by [org.slf4j#slf4j-api;1.7.36] in [default]\n",
            "\t---------------------------------------------------------------------\n",
            "\t|                  |            modules            ||   artifacts   |\n",
            "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
            "\t---------------------------------------------------------------------\n",
            "\t|      default     |   15  |   14  |   14  |   2   ||   13  |   13  |\n",
            "\t---------------------------------------------------------------------\n",
            ":: retrieving :: org.apache.spark#spark-submit-parent-359ca99f-85f7-42b0-afe4-8f46090c0b97\n",
            "\tconfs: [default]\n",
            "\t13 artifacts copied, 0 already retrieved (62765kB/116ms)\n",
            "23/08/18 06:25:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
            "Welcome to\n",
            "      ____              __\n",
            "     / __/__  ___ _____/ /__\n",
            "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
            "   /__ / .__/\\_,_/_/ /_/\\_\\   version 3.4.1\n",
            "      /_/\n",
            "\n",
            "Using Python version 3.10.12 (main, Jun 11 2023 05:26:28)\n",
            "Spark context Web UI available at http://01781661e466:4040\n",
            "Spark context available as 'sc' (master = local[*], app id = local-1692339955044).\n",
            "SparkSession available as 'spark'.\n",
            ">>> from pyspark.sql import functions as F\n",
            ">>> from pyspark.sql.types import StructType, StringType\n",
            ">>> kafka_brokers = \"localhost:9092\"\n",
            ">>> def console_output(df, freq):\n",
            "...     return df.writeStream \\\n",
            "...         .format(\"console\") \\\n",
            "...         .trigger(processingTime='%s seconds' % freq ) \\\n",
            "...         .options(truncate=True) \\\n",
            "...         .start()\n",
            "... \n",
            ">>> raw_orders = spark.read. \\\n",
            "...     format(\"kafka\"). \\\n",
            "...     option(\"kafka.bootstrap.servers\", kafka_brokers). \\\n",
            "...     option(\"subscribe\", \"gpa\"). \\\n",
            "...     option(\"startingOffsets\", \"earliest\"). \\\n",
            "...     load()\n",
            ">>> raw_orders.show()\n",
            "23/08/18 06:30:26 WARN AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.\n",
            "+----+--------------------+-----+---------+------+--------------------+-------------+\n",
            "| key|               value|topic|partition|offset|           timestamp|timestampType|\n",
            "+----+--------------------+-----+---------+------+--------------------+-------------+\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|     0|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|     1|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|     2|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|     3|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|     4|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|     5|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|     6|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|     7|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|     8|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|     9|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|    10|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|    11|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|    12|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|    13|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|    14|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|    15|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|    16|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|    17|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|    18|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|    19|2023-08-18 06:25:...|            0|\n",
            "+----+--------------------+-----+---------+------+--------------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n",
            ">>> raw_orders.printSchema()\n",
            "root\n",
            " |-- key: binary (nullable = true)\n",
            " |-- value: binary (nullable = true)\n",
            " |-- topic: string (nullable = true)\n",
            " |-- partition: integer (nullable = true)\n",
            " |-- offset: long (nullable = true)\n",
            " |-- timestamp: timestamp (nullable = true)\n",
            " |-- timestampType: integer (nullable = true)\n",
            "\n",
            ">>> raw_orders = spark.readStream. \\\n",
            "...     format(\"kafka\"). \\\n",
            "...     option(\"kafka.bootstrap.servers\", kafka_brokers). \\\n",
            "...     option(\"subscribe\", \"gpa\"). \\\n",
            "...     option(\"startingOffsets\", \"earliest\"). \\\n",
            "...     option(\"maxOffsetsPerTrigger\", \"5\"). \\\n",
            "...     load()\n",
            ">>> out = console_output(raw_orders, 5)\n",
            "23/08/18 06:31:50 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-24fd33be-1796-44b3-a054-b79eb238d45f. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
            "23/08/18 06:31:50 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n",
            ">>> 23/08/18 06:31:50 WARN AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.\n",
            "-------------------------------------------\n",
            "Batch: 0\n",
            "-------------------------------------------\n",
            "+----+--------------------+-----+---------+------+--------------------+-------------+\n",
            "| key|               value|topic|partition|offset|           timestamp|timestampType|\n",
            "+----+--------------------+-----+---------+------+--------------------+-------------+\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|     0|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|     1|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|     2|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|     3|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|     4|2023-08-18 06:25:...|            0|\n",
            "+----+--------------------+-----+---------+------+--------------------+-------------+\n",
            "\n",
            "-------------------------------------------\n",
            "Batch: 1\n",
            "-------------------------------------------\n",
            "+----+--------------------+-----+---------+------+--------------------+-------------+\n",
            "| key|               value|topic|partition|offset|           timestamp|timestampType|\n",
            "+----+--------------------+-----+---------+------+--------------------+-------------+\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|     5|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|     6|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|     7|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|     8|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|     9|2023-08-18 06:25:...|            0|\n",
            "+----+--------------------+-----+---------+------+--------------------+-------------+\n",
            "\n",
            "-------------------------------------------\n",
            "Batch: 2\n",
            "-------------------------------------------\n",
            "+----+--------------------+-----+---------+------+--------------------+-------------+\n",
            "| key|               value|topic|partition|offset|           timestamp|timestampType|\n",
            "+----+--------------------+-----+---------+------+--------------------+-------------+\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|    10|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|    11|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|    12|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|    13|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|    14|2023-08-18 06:25:...|            0|\n",
            "+----+--------------------+-----+---------+------+--------------------+-------------+\n",
            "\n",
            "-------------------------------------------\n",
            "Batch: 3\n",
            "-------------------------------------------\n",
            "+----+--------------------+-----+---------+------+--------------------+-------------+\n",
            "| key|               value|topic|partition|offset|           timestamp|timestampType|\n",
            "+----+--------------------+-----+---------+------+--------------------+-------------+\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|    15|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|    16|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|    17|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|    18|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|    19|2023-08-18 06:25:...|            0|\n",
            "+----+--------------------+-----+---------+------+--------------------+-------------+\n",
            "\n",
            "-------------------------------------------\n",
            "Batch: 4\n",
            "-------------------------------------------\n",
            "+----+--------------------+-----+---------+------+--------------------+-------------+\n",
            "| key|               value|topic|partition|offset|           timestamp|timestampType|\n",
            "+----+--------------------+-----+---------+------+--------------------+-------------+\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|    20|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|    21|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|    22|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|    23|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|    24|2023-08-18 06:25:...|            0|\n",
            "+----+--------------------+-----+---------+------+--------------------+-------------+\n",
            "\n",
            "-------------------------------------------\n",
            "Batch: 5\n",
            "-------------------------------------------\n",
            "+----+--------------------+-----+---------+------+--------------------+-------------+\n",
            "| key|               value|topic|partition|offset|           timestamp|timestampType|\n",
            "+----+--------------------+-----+---------+------+--------------------+-------------+\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|    25|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|    26|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|    27|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|    28|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|    29|2023-08-18 06:25:...|            0|\n",
            "+----+--------------------+-----+---------+------+--------------------+-------------+\n",
            "\n",
            "-------------------------------------------\n",
            "Batch: 6\n",
            "-------------------------------------------\n",
            "+----+--------------------+-----+---------+------+--------------------+-------------+\n",
            "| key|               value|topic|partition|offset|           timestamp|timestampType|\n",
            "+----+--------------------+-----+---------+------+--------------------+-------------+\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|    30|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|    31|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|    32|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|    33|2023-08-18 06:25:...|            0|\n",
            "|null|[7B 22 6F 62 73 2...|  gpa|        1|    34|2023-08-18 06:25:...|            0|\n",
            "+----+--------------------+-----+---------+------+--------------------+-------------+\n",
            "\n",
            "out.stop()\n",
            ">>> schema = StructType() \\\n",
            "...     .add(\"obs\", StringType()) \\\n",
            "...     .add(\"gpa\", StringType()) \\\n",
            "...     .add(\"iq\", StringType()) \\\n",
            "...     .add(\"gender\", StringType()) \\\n",
            "...     .add(\"concept\", StringType())\n",
            ">>> value_orders = raw_orders \\\n",
            "...     .select(F.from_json(F.col(\"value\").cast(\"String\"), schema).alias(\"value\"), \"offset\")\n",
            ">>> value_orders.printSchema()\n",
            "root\n",
            " |-- value: struct (nullable = true)\n",
            " |    |-- obs: string (nullable = true)\n",
            " |    |-- gpa: string (nullable = true)\n",
            " |    |-- iq: string (nullable = true)\n",
            " |    |-- gender: string (nullable = true)\n",
            " |    |-- concept: string (nullable = true)\n",
            " |-- offset: long (nullable = true)\n",
            "\n",
            ">>> parsed_orders = value_orders.select(\"value.*\", \"offset\")\n",
            ">>> parsed_orders.printSchema()\n",
            "root\n",
            " |-- obs: string (nullable = true)\n",
            " |-- gpa: string (nullable = true)\n",
            " |-- iq: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- concept: string (nullable = true)\n",
            " |-- offset: long (nullable = true)\n",
            "\n",
            ">>> out = console_output(parsed_orders, 5)\n",
            "23/08/18 06:35:01 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-188f1f08-1b99-477c-b5e7-65873cd4a99a. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
            "23/08/18 06:35:01 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n",
            ">>> 23/08/18 06:35:01 WARN AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.\n",
            "-------------------------------------------\n",
            "Batch: 0\n",
            "-------------------------------------------\n",
            "+---+-----+---+------+-------+------+\n",
            "|obs|  gpa| iq|gender|concept|offset|\n",
            "+---+-----+---+------+-------+------+\n",
            "|  1| 7.94|111|     2|     67|     0|\n",
            "|  2|8.292|107|     2|     43|     1|\n",
            "|  3|4.643|100|     2|     52|     2|\n",
            "|  4| 7.47|107|     2|     66|     3|\n",
            "|  5|8.882|114|     1|     58|     4|\n",
            "+---+-----+---+------+-------+------+\n",
            "\n",
            "-------------------------------------------\n",
            "Batch: 1\n",
            "-------------------------------------------\n",
            "+---+-----+---+------+-------+------+\n",
            "|obs|  gpa| iq|gender|concept|offset|\n",
            "+---+-----+---+------+-------+------+\n",
            "|  6|7.585|115|     2|     51|     5|\n",
            "|  7| 7.65|111|     2|     71|     6|\n",
            "|  8|2.412| 97|     2|     51|     7|\n",
            "|  9|    6|100|     1|     49|     8|\n",
            "| 10|8.833|112|     2|     51|     9|\n",
            "+---+-----+---+------+-------+------+\n",
            "\n",
            "-------------------------------------------\n",
            "Batch: 2\n",
            "-------------------------------------------\n",
            "+---+-----+---+------+-------+------+\n",
            "|obs|  gpa| iq|gender|concept|offset|\n",
            "+---+-----+---+------+-------+------+\n",
            "| 11| 7.47|104|     1|     35|    10|\n",
            "| 12|5.528| 89|     1|     54|    11|\n",
            "| 13|7.167|104|     2|     54|    12|\n",
            "| 14|7.571|102|     1|     64|    13|\n",
            "| 15|  4.7| 91|     1|     56|    14|\n",
            "+---+-----+---+------+-------+------+\n",
            "\n",
            "-------------------------------------------\n",
            "Batch: 3\n",
            "-------------------------------------------\n",
            "+---+-----+---+------+-------+------+\n",
            "|obs|  gpa| iq|gender|concept|offset|\n",
            "+---+-----+---+------+-------+------+\n",
            "| 16|8.167|114|     1|     69|    15|\n",
            "| 17|7.822|114|     1|     55|    16|\n",
            "| 18|7.598|103|     1|     65|    17|\n",
            "| 19|    4|106|     2|     40|    18|\n",
            "| 20|6.231|105|     1|     66|    19|\n",
            "+---+-----+---+------+-------+------+\n",
            "\n",
            "out.stop()\n",
            ">>> def console_output_ckeckpointed(df, freq):\n",
            "...      return  df.writeStream \\\n",
            "...          .format(\"console\") \\\n",
            "...          .trigger(processingTime=f'{freq} seconds') \\\n",
            "...          .option(\"truncate\", False) \\\n",
            "...          .option(\"checkpointLocation\", \"gpa_checkpoint\") \\\n",
            "...          .start()\n",
            "... \n",
            ">>> out = console_output_ckeckpointed(parsed_orders, 5)\n",
            "23/08/18 06:38:01 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n",
            ">>> 23/08/18 06:38:01 WARN AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.\n",
            "-------------------------------------------\n",
            "Batch: 0\n",
            "-------------------------------------------\n",
            "+---+-----+---+------+-------+------+\n",
            "|obs|gpa  |iq |gender|concept|offset|\n",
            "+---+-----+---+------+-------+------+\n",
            "|1  |7.94 |111|2     |67     |0     |\n",
            "|2  |8.292|107|2     |43     |1     |\n",
            "|3  |4.643|100|2     |52     |2     |\n",
            "|4  |7.47 |107|2     |66     |3     |\n",
            "|5  |8.882|114|1     |58     |4     |\n",
            "+---+-----+---+------+-------+------+\n",
            "\n",
            "-------------------------------------------\n",
            "Batch: 1\n",
            "-------------------------------------------\n",
            "+---+-----+---+------+-------+------+\n",
            "|obs|gpa  |iq |gender|concept|offset|\n",
            "+---+-----+---+------+-------+------+\n",
            "|6  |7.585|115|2     |51     |5     |\n",
            "|7  |7.65 |111|2     |71     |6     |\n",
            "|8  |2.412|97 |2     |51     |7     |\n",
            "|9  |6    |100|1     |49     |8     |\n",
            "|10 |8.833|112|2     |51     |9     |\n",
            "+---+-----+---+------+-------+------+\n",
            "\n",
            "-------------------------------------------\n",
            "Batch: 2\n",
            "-------------------------------------------\n",
            "+---+-----+---+------+-------+------+\n",
            "|obs|gpa  |iq |gender|concept|offset|\n",
            "+---+-----+---+------+-------+------+\n",
            "|11 |7.47 |104|1     |35     |10    |\n",
            "|12 |5.528|89 |1     |54     |11    |\n",
            "|13 |7.167|104|2     |54     |12    |\n",
            "|14 |7.571|102|1     |64     |13    |\n",
            "|15 |4.7  |91 |1     |56     |14    |\n",
            "+---+-----+---+------+-------+------+\n",
            "\n",
            "out.stop()\n",
            ">>> exit()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from pyspark.sql import functions as F\n",
        "# from pyspark.sql.types import StructType, StringType\n",
        "\n",
        "# kafka_brokers = \"localhost:9092\"\n",
        "\n",
        "# #функция, чтобы выводить на консоль вместо show()\n",
        "# def console_output(df, freq):\n",
        "#     return df.writeStream \\\n",
        "#         .format(\"console\") \\\n",
        "#         .trigger(processingTime='%s seconds' % freq ) \\\n",
        "#         .options(truncate=True) \\\n",
        "#         .start()\n",
        "\n",
        "# #читаем без стрима\n",
        "# raw_orders = spark.read. \\\n",
        "#     format(\"kafka\"). \\\n",
        "#     option(\"kafka.bootstrap.servers\", kafka_brokers). \\\n",
        "#     option(\"subscribe\", \"gpa\"). \\\n",
        "#     option(\"startingOffsets\", \"earliest\"). \\\n",
        "#     load()\n",
        "\n",
        "# raw_orders.show()"
      ],
      "metadata": {
        "id": "uwfGjJUJiEJE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# raw_orders.printSchema()"
      ],
      "metadata": {
        "id": "4sw3UwDqiK9a"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# raw_orders = spark.readStream. \\\n",
        "#     format(\"kafka\"). \\\n",
        "#     option(\"kafka.bootstrap.servers\", kafka_brokers). \\\n",
        "#     option(\"subscribe\", \"gpa\"). \\\n",
        "#     option(\"startingOffsets\", \"earliest\"). \\\n",
        "#     option(\"maxOffsetsPerTrigger\", \"5\"). \\\n",
        "#     load()\n",
        "\n",
        "# out = console_output(raw_orders, 5)"
      ],
      "metadata": {
        "id": "jKJrQn42iP1Z"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# out.stop()"
      ],
      "metadata": {
        "id": "ecZ549VEiSKR"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# schema = StructType() \\\n",
        "#     .add(\"obs\", StringType()) \\\n",
        "#     .add(\"gpa\", StringType()) \\\n",
        "#     .add(\"iq\", StringType()) \\\n",
        "#     .add(\"gender\", StringType()) \\\n",
        "#     .add(\"concept\", StringType())\n",
        "\n",
        "\n",
        "# value_orders = raw_orders \\\n",
        "#     .select(F.from_json(F.col(\"value\").cast(\"String\"), schema).alias(\"value\"), \"offset\")\n",
        "\n",
        "# value_orders.printSchema()"
      ],
      "metadata": {
        "id": "czLzyXwTiXxw"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parsed_orders = value_orders.select(\"value.*\", \"offset\")\n",
        "\n",
        "# parsed_orders.printSchema()"
      ],
      "metadata": {
        "id": "VxeedQRRiazH"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# out = console_output(parsed_orders, 5)"
      ],
      "metadata": {
        "id": "L-fJD7BoigDP"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# out.stop()"
      ],
      "metadata": {
        "id": "Gacfx4Ubiiuv"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def console_output_ckeckpointed(df, freq):\n",
        "#      return  df.writeStream \\\n",
        "#          .format(\"console\") \\\n",
        "#          .trigger(processingTime=f'{freq} seconds') \\\n",
        "#          .option(\"truncate\", False) \\\n",
        "#          .option(\"checkpointLocation\", \"gpa_checkpoint\") \\\n",
        "#          .start()"
      ],
      "metadata": {
        "id": "kL1EPyefwdAN"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# out = console_output_ckeckpointed(parsed_orders, 5)"
      ],
      "metadata": {
        "id": "L1DsZqTwwobK"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# out.stop()"
      ],
      "metadata": {
        "id": "WWE9w6mZwtIa"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# exit()"
      ],
      "metadata": {
        "id": "dl1xYYgyiUi4"
      },
      "execution_count": 29,
      "outputs": []
    }
  ]
}